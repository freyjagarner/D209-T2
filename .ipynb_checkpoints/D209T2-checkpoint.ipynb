{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4600513e-c07f-45ab-ba82-ffb688199f41",
   "metadata": {},
   "source": [
    "#### Chelsey De Dios\n",
    "\n",
    "# D209 Task 2: Predictive Analysis\n",
    "\n",
    "## Part I: Research Question\n",
    "\n",
    "### A.  Describe the purpose of this data mining report by doing the following:\n",
    "\n",
    "#### 1.  Propose one question relevant to a real-world organizational situation that you will answer using one of the following prediction methods:\n",
    "\n",
    "* decision trees\n",
    "\n",
    "* random forests\n",
    "\n",
    "* advanced regression (i.e., lasso or ridge regression)\n",
    "\n",
    "In this analysis we will be asking whether we can predict a customer's tenure based on other data about the customer using Random Forest.\n",
    "\n",
    "#### 2.  Define one goal of the data analysis. Ensure that your goal is reasonable within the scope of the scenario and is represented in the available data.\n",
    "\n",
    "The goal of this analysis will to predict customer tenure based on other data points regarding the customer, such as demographic and service related data.\n",
    " \n",
    "\n",
    "## Part II: Method Justification\n",
    "\n",
    "### B.  Explain the reasons for your chosen prediction method from part A1 by doing the following:\n",
    "\n",
    "#### 1.  Explain how the prediction method you chose analyzes the selected data set. Include expected outcomes.\n",
    "\n",
    "Random Forest Regression fits regression models of the explanatory variables to the target variables, and then splits the data for each of the explanatory variables. After theis, the sum of squared error is calculated at the points between the actual and predicted values. The lowest sum of squared error is chosen and the process continues until all data is analyzed.\n",
    "\n",
    "The expected outcome in this case would be that the algorithm identifies customers tenure based on the results of these calculations.\n",
    "\n",
    "#### 2.  Summarize one assumption of the chosen prediction method.\n",
    "\n",
    "This model assumes that for each explanatory variable there is a 'best split' that will eventually lead to the correct identification of the target variable.\n",
    "\n",
    "#### 3.  List the packages or libraries you have chosen for Python or R, and justify how each item on the list supports the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686c922d-701b-4369-bb49-01970efdf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be2379-8298-48b0-8249-09e278e5552d",
   "metadata": {},
   "source": [
    "a. Pandas allows us to work with the data through dataframes which allow for various simple data manipulations.\n",
    "\n",
    "b. Numpy allows us to work with arrays of data, and is needed for some Pandas manipulations.\n",
    "\n",
    "c. seaborn and matplotlib pyplot allow us to create visualizations easily so we can look at our data graphically.\n",
    "\n",
    "d. sklearn allows us to use their machine learning algorithms in a black box manner, and to transform our data to work with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217e7b0-f256-40d7-9f09-493f52dc7161",
   "metadata": {},
   "source": [
    "## Part III: Data Preparation\n",
    "\n",
    "### C.  Perform data preparation for the chosen data set by doing the following:\n",
    "\n",
    "#### 1.  Describe one data preprocessing goal relevant to the prediction method from part A1.\n",
    "\n",
    "Data will be encoded into dummy variables in order to be numeric which allows it to work with the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe49720-4cbf-45ea-a00a-4ef337658b8b",
   "metadata": {},
   "source": [
    "#### 2.  Identify the initial data set variables that you will use to perform the analysis for the prediction question from part A1, and group each variable as continuous or categorical. \n",
    "\n",
    "This is performed below.\n",
    "\n",
    "#### 3.  Explain the steps used to prepare the data for the analysis. Identify the code segment for each step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38e75db-0ab2-460c-8df6-bbd38eadc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from csv\n",
    "df = pd.read_csv('churn_clean.csv')\n",
    "\n",
    "# set it so we can see all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd4bf4-3cba-4d7a-8bd1-9f1e0bd29229",
   "metadata": {},
   "source": [
    "##### a. Change Column Names\n",
    "\n",
    "It is useful to change the column names in order to better identify non-descriptive variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3a3513-78b3-4453-b605-c151193eae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of current column names mapping to desired column names\n",
    "survey_dict = {'Item1':'timely_responses', \n",
    "               'Item2':'timely_fixes', \n",
    "               'Item3':'timely_replacements', \n",
    "               'Item4':'reliability', \n",
    "               'Item5':'options', \n",
    "               'Item6':'respectful_response', \n",
    "               'Item7':'courteous_exchange', \n",
    "               'Item8':'evidence_of_active_listening'}\n",
    "\n",
    "# rename the column names based on survey_dict\n",
    "df = df.rename(columns=survey_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3981b-911e-4ef3-a67e-b1fa53d1dbe9",
   "metadata": {},
   "source": [
    "##### b. Change Data Types\n",
    "\n",
    "Now we will change the datatypes of our columns by passing a dictionary to df.astype mapping our column names to their new typing. We will do this because models will recognize the variable's datatype and deal with data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e030a71a-8ada-4445-90a2-3a42e023c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dataframe columns to more appropriate data types\n",
    "df = df.astype({'Population':int, \n",
    "                'Area':'category',\n",
    "                'Children':int, \n",
    "                'Age':int,\n",
    "                'Income':float, \n",
    "                'Marital':'category', \n",
    "                'Gender':'category', \n",
    "                'Churn':'category',\n",
    "                'Outage_sec_perweek':float, \n",
    "                'Email':int, \n",
    "                'Contacts':int, \n",
    "                'Yearly_equip_failure':int,\n",
    "                'Techie':'category', \n",
    "                'Contract':'category', \n",
    "                'Port_modem':'category', \n",
    "                'Tablet':'category', \n",
    "                'InternetService':'category',\n",
    "                'Phone':'category', \n",
    "                'Multiple':'category', \n",
    "                'OnlineSecurity':'category', \n",
    "                'OnlineBackup':'category',\n",
    "                'DeviceProtection':'category', \n",
    "                'TechSupport':'category', \n",
    "                'StreamingTV':'category', \n",
    "                'StreamingMovies':'category',\n",
    "                'PaperlessBilling':'category', \n",
    "                'PaymentMethod':'category', \n",
    "                'Tenure':float, \n",
    "                'MonthlyCharge':float,\n",
    "                'Bandwidth_GB_Year':float, \n",
    "                'timely_responses':int, \n",
    "                'timely_fixes':int, \n",
    "                'timely_replacements':int, \n",
    "                'reliability':int, \n",
    "                'options':int,\n",
    "                'respectful_response':int, \n",
    "                'courteous_exchange':int, \n",
    "                'evidence_of_active_listening':int}, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770c790f-c55d-443f-89ae-b0bb7ce09aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the dataframe to relevant variables\n",
    "df = df[['Population', 'Area', 'Age', 'Gender', 'Children', 'Marital', 'Income',\n",
    "         'Outage_sec_perweek', 'Email', 'Contacts', 'Yearly_equip_failure',\n",
    "         'Techie', 'Contract', 'Port_modem', 'Tablet', 'InternetService',\n",
    "         'Phone', 'Multiple', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "         'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', \n",
    "         'PaymentMethod', 'Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year',\n",
    "         'timely_responses', 'timely_fixes', 'timely_replacements', 'reliability',\n",
    "         'options', 'respectful_response', 'courteous_exchange', \n",
    "         'evidence_of_active_listening', 'Churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562c0ad2-83bb-443a-84c9-be884cf75dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable and DataType\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Children</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outage_sec_perweek</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contacts</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yearly_equip_failure</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Techie</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Port_modem</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tablet</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternetService</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineBackup</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceProtection</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TechSupport</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamingTV</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamingMovies</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaymentMethod</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyCharge</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bandwidth_GB_Year</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timely_responses</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timely_fixes</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timely_replacements</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reliability</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respectful_response</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>courteous_exchange</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence_of_active_listening</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DataType\n",
       "Population                        numeric\n",
       "Area                          categorical\n",
       "Age                               numeric\n",
       "Gender                        categorical\n",
       "Children                          numeric\n",
       "Marital                       categorical\n",
       "Income                        categorical\n",
       "Outage_sec_perweek            categorical\n",
       "Email                             numeric\n",
       "Contacts                          numeric\n",
       "Yearly_equip_failure              numeric\n",
       "Techie                        categorical\n",
       "Contract                      categorical\n",
       "Port_modem                    categorical\n",
       "Tablet                        categorical\n",
       "InternetService               categorical\n",
       "Phone                         categorical\n",
       "Multiple                      categorical\n",
       "OnlineSecurity                categorical\n",
       "OnlineBackup                  categorical\n",
       "DeviceProtection              categorical\n",
       "TechSupport                   categorical\n",
       "StreamingTV                   categorical\n",
       "StreamingMovies               categorical\n",
       "PaperlessBilling              categorical\n",
       "PaymentMethod                 categorical\n",
       "Tenure                        categorical\n",
       "MonthlyCharge                 categorical\n",
       "Bandwidth_GB_Year             categorical\n",
       "timely_responses                  numeric\n",
       "timely_fixes                      numeric\n",
       "timely_replacements               numeric\n",
       "reliability                       numeric\n",
       "options                           numeric\n",
       "respectful_response               numeric\n",
       "courteous_exchange                numeric\n",
       "evidence_of_active_listening      numeric\n",
       "Churn                         categorical"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of variables with classification of categorical or numeric\n",
    "print('Variable and DataType')\n",
    "types = pd.DataFrame(['numeric' if df[i].dtypes == (int or float) \n",
    "                      else 'categorical' for i in df.columns], df.columns, columns=['DataType'])\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60b50e-ca29-4f00-8ce9-ec87a4c6d394",
   "metadata": {},
   "source": [
    "Above all of the variables used in this analysis and their datatypes are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f948f7-a03d-49ab-a916-00a3eb98315d",
   "metadata": {},
   "source": [
    "##### c. Get dummy variables for categorical data\n",
    "\n",
    "Here we will first replace all binary values in variables with 1's and 0's. Then, using pd.getdummies we will get dummy variables/one hot encoded variables to make our categorical data numeric in order to work with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08355b9e-325b-4537-aea0-72b596cd611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of columns with target at the end\n",
    "ordered_cols = [i for i in df.columns if i != 'Tenure'] + ['Tenure']\n",
    "\n",
    "# reorder columns to get target variable last\n",
    "ordered_df = df[ordered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df55533a-15bd-4e9d-a8e6-8deac2f79e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all Yes/No values with 1 and 0 in all columns except target'\n",
    "dummy_df = ordered_df[ordered_df.columns[:-1]].replace({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ee01fc-3ef7-4be4-a86a-d95d9ff5261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy values for dataframe\n",
    "dummy_df = pd.get_dummies(dummy_df)\n",
    "\n",
    "# append churn to dummy_df\n",
    "dummy_df['Tenure'] = ordered_df['Tenure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff0e3a86-b2ab-4f89-884f-112a5c7948b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric datatype columns list\n",
    "num_cols = set(df._get_numeric_data().columns)\n",
    "\n",
    "# get categorical datatype columns list except target\n",
    "cat_cols = set(df.columns) - num_cols\n",
    "cat_cols.remove('Churn')\n",
    "\n",
    "# get categorical dtype columns in dummy_df\n",
    "dummy_cats = list(set(dummy_df.columns) - num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ef188f-cff7-4bbd-8180-4fb5a83d71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical data back to category\n",
    "dummy_df[dummy_cats] = dummy_df[dummy_cats].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9997a6-4747-40a4-8615-7d943bdca20b",
   "metadata": {},
   "source": [
    "##### d. Scale Numerical Data\n",
    "\n",
    "Now we will use sklearn's StandardScaler to scale our numeric data so nothing is improperly weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b2b7cc-36d3-4123-9a31-f0fd537c9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "dummy_df[list(num_cols)] = scaler.fit_transform(dummy_df[list(num_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7622d-e299-4d59-92e2-83c98e614984",
   "metadata": {},
   "source": [
    "##### e. Reorder Columns for Target Variable\n",
    "\n",
    "Next we will reorder our columns to put our target variable 'Churn' at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b26cab-dd1e-414c-8ceb-d43a838b7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order columns to get target variable to the end\n",
    "ordered_cols = [i for i in dummy_df.columns if i != 'Tenure'] + ['Tenure']\n",
    "dummy_df = dummy_df[ordered_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ff6b3-4530-4bdb-acaa-3bf08cf2bfdf",
   "metadata": {},
   "source": [
    "#### 4.  Provide a copy of the cleaned data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421173b1-c9d1-4021-bb6c-5f33746bb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('t2_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2db461-3ff4-45fa-b9ee-fb1dd7ff6b09",
   "metadata": {},
   "source": [
    "## Part IV: Analysis\n",
    "\n",
    "### D.  Perform the data analysis and report on the results by doing the following:\n",
    "\n",
    "#### 1.  Split the data into training and test data sets and provide the file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fecb3fae-6ec2-4e09-bf4a-f95b0bf0f73c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train/test sets\n",
    "train, test = train_test_split(dummy_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "295f7657-9a38-4bdf-87e8-071387948e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export training data to csv\n",
    "train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08531853-e92c-4adb-b0f1-6a08cd867cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export test data to csv\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f4cf83b-8577-4378-bf86-fc454dbf2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into explanatory and target variables\n",
    "X_train, y_train, X_test, y_test = train.iloc[:,0:-1], train.iloc[:,-1:], test.iloc[:,0:-1], test.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa716326-8fcf-46bc-a96b-d6613b6abd79",
   "metadata": {},
   "source": [
    "#### 2.  Describe the analysis technique you used to appropriately analyze the data. Include screenshots of the intermediate calculations you performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcce375-492f-46eb-9b27-6f44ea4d73e8",
   "metadata": {},
   "source": [
    "The first analysis is going to be the accuracy score, which is the fraction of correctly identified data to all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5158558-1a5c-4af1-829c-55f6750938b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997191402856261"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(random_state=42).fit(X_train, y_train.values.ravel())\n",
    "rfr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af0639-a67f-4bb1-baa3-04f99f8c253f",
   "metadata": {},
   "source": [
    "Our accuracy score is very nearly 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733294da-5ab7-40ec-994c-a32da08885fc",
   "metadata": {},
   "source": [
    "The second calculation will be the mean squared error, which is the average of the square of the errors, or how far away the model's predicition is from each true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e0be5f4-6704-44a7-adca-9e13cca2d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019252786024908436"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = rfr.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a5a73-ae6c-4be9-8919-b95b8d5809e6",
   "metadata": {},
   "source": [
    "The mean squared error is around .0019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623e6e0-31de-46f2-8792-b83a1ea52ee6",
   "metadata": {},
   "source": [
    "#### 3.  Provide the code used to perform the prediction analysis from part D2.\n",
    " \n",
    "\n",
    "## Part V: Data Summary and Implications\n",
    "\n",
    "### E.  Summarize your data analysis by doing the following:\n",
    "\n",
    "#### 1.  Explain the accuracy and the mean squared error (MSE) of your prediction model.\n",
    "\n",
    "The accuracy score of the model is around 99.9%, which is almost perfect. This could be due to the relationship of Tenure and Bandwidth_GB_Year which we have discovered in previous exercises. The MSE is .0019 which is very low, which makes sense in regards to our findings with accuracy. The model has a very high accuracy and thus the average of the errors, or how far our prediciton deviates from the true value, is very low.\n",
    "\n",
    "#### 2.  Discuss the results and implications of your prediction analysis.\n",
    "\n",
    "The result of this analysis is a near-perfect model of customer tenure based on other datapoints. If this were a real dataset, it would mean that this model would almost always correctly identify a customer's tenure based on the other data collected about them located in this dataset. \n",
    "\n",
    "#### 3.  Discuss one limitation of your data analysis.\n",
    "\n",
    "One limitation of this analysis is that there are only 10,000 entries for customer data, and we do not know the true population size of customers to compare and decide if this model it truly as valuable as the scoring suggests.\n",
    "\n",
    "#### 4.  Recommend a course of action for the real-world organizational situation from part A1 based on your results and implications discussed in part E2.\n",
    "\n",
    "Based on the findings in this predictive it is possible to guess a customer's tenure based on the other information about them in this dataset. It would be good to use this to find the relationship between customers with a higher tenure to then figure out what causes some customers to stay and others to go.\n",
    "\n",
    "## Part VI: Demonstration\n",
    "\n",
    "### F.  Provide a Panopto video recording that includes a demonstration of the functionality of the code used for the analysis and a summary of the programming environment.\n",
    "\n",
    "https://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a9e9b773-a451-451d-8d31-addb01800d9b\n",
    "\n",
    "### G.  Record the web sources used to acquire data or segments of third-party code to support the analysis. Ensure the web sources are reliable.\n",
    " \n",
    "N/A\n",
    "\n",
    "### H.  Acknowledge sources, using in-text citations and references, for content that is quoted, paraphrased, or summarized.\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3674d-2691-4556-b0b3-cb19481fcacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
